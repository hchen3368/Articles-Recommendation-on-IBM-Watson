{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./watson_image.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# <a id=\"asso-title\"> Recommendations for Articles with IBM </a>\n",
    "\n",
    "\n",
    "### Building a recommendation system for data science articles on the IBM Watson Studio. \n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "\n",
    "## <a id=\"toc\">  Table of Content. </a>\n",
    "\n",
    "- Notebook I: Data Collection, Cleaning, and EDA.\n",
    "\n",
    "\n",
    "- Notebook II: Rank-Based Recommendations and Neighbor Collaborative Filtering.\n",
    "\n",
    "\n",
    "- Notebook III: Matrix Factorization Collaborative Filtering.\n",
    "\n",
    "\n",
    "- Notebook IV: More EDA, Preprocessing, Content-based Recommendation.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"notebook1\"> This is Notebook II: Rank-based, neighbor collaborative filtering.</a>\n",
    "\n",
    "0. [Data Loading.](#Loading)<br>\n",
    "\n",
    "\n",
    "Part A: Rank-based Recommendation (\"Popular/Trending...\")\n",
    "\n",
    "1. [Ranking and Recommendation](#Rank)<br>\n",
    "\n",
    "        \n",
    "Part B: Neighbor-based Collabrative Filtering \n",
    "\n",
    "(\"People watch spongebob-squarepants also watch...\")    \n",
    "     \n",
    "2. [Data Preprocessing: user-item matrix.](#user-item)<br>\n",
    "    \n",
    "\n",
    "3. [Similar users and Collabrative Filtering.](#user-user)<br>\n",
    "\n",
    "    \n",
    "4. [Data Saving.](#save)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Python 3 environment, with Anaconda distribution of standard libraries.\n",
    "# Additional module may needed: pickle.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Loading\"> 0. Data Loading and Overview.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0        1430  using pixiedust for fast, flexible, and easier...        1\n",
       "1        1314       healthcare python streaming application demo        2\n",
       "2        1429         use deep learning for image classification        3\n",
       "3        1338          ml optimization using cognitive assistant        4\n",
       "4        1276          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a prepared dataset to start with\n",
    "# We shall collect more data via the IBM Watson API later\n",
    "with open('1_data_df.pkl', 'rb') as pickle1:\n",
    "    df = pickle.load(pickle1)\n",
    "    \n",
    "with open('1_data_df_content.pkl', 'rb') as pickle2:\n",
    "    df_content = pickle.load(pickle2)\n",
    "\n",
    "# overview of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1  Communicating data science: A guide to present...       Live           1  \n",
       "2         This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3  DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live           4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overview of df_content \n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Rank\">1. Ranking and Recommendation by Popularity .</a>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data, we can extract the number of interactions of a user with an article. However, it is not clear that the numbers can be interpreted as ratings for whether a user liked an article or not.  \n",
    "\n",
    "With these considerations, we shall treat interactions between users and articles as binary, namely weather or not someone read an article, and disregard the number of times they read it.\n",
    "\n",
    "We first define a function to rank articles in this way. And use it to find popular items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank articles by how many users have read it.\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article id's\n",
    "    \n",
    "    '''\n",
    "    top_articles=df.groupby('article_id').count().sort_values('title', ascending=False).index[:n]\n",
    " \n",
    "    return list(top_articles) # Return the top article ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1429, 1330, 1431, 1427, 1364, 1314, 1293, 1170, 1162, 1304]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_article_ids(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return article titles given article ids\n",
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    \n",
    "    article_names = [df[df.article_id==x].title.unique()[0] for x in article_ids if sum(df.article_id==x)>0]\n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use deep learning for image classification',\n",
       " 'insights from new york car accident reports',\n",
       " 'visualize car data with brunel',\n",
       " 'use xgboost, scikit-learn & ibm watson machine learning apis',\n",
       " 'predicting churn with the spss random tree algorithm',\n",
       " 'healthcare python streaming application demo',\n",
       " 'finding optimal locations of new store using decision optimization',\n",
       " 'apache spark lab, part 1: basic concepts',\n",
       " 'analyze energy consumption in buildings',\n",
       " 'gosales transactions for logistic regression model']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_names(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    \n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    item_id - a column name in df to groupby with\n",
    "    user_id - a column name in df to count\n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    top_articles = get_article_names(get_top_article_ids(n,df=df))\n",
    "    \n",
    "    return top_articles # Return the top article titles from df (not df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use deep learning for image classification',\n",
       " 'insights from new york car accident reports',\n",
       " 'visualize car data with brunel',\n",
       " 'use xgboost, scikit-learn & ibm watson machine learning apis',\n",
       " 'predicting churn with the spss random tree algorithm']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_articles(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Neighbor Based Collaborative Filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"user-item\">2. Data-Preprocessing: user-item matrix.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reformat the **df** dataframe to be shaped with users as the rows and articles as the columns.  \n",
    "\n",
    "* Each **user** appear in each **row** once.\n",
    "\n",
    "\n",
    "* Each **article** show up in one **column**.  \n",
    "\n",
    "\n",
    "* **If a user has interacted with an article, then place a 1 where the user-row meets for that article-column**.  It does not matter how many times a user has interacted with the article, all entries where a user has interacted with an article should be a 1.  \n",
    "\n",
    "\n",
    "* **If a user has not interacted with an item, then place a zero where the user-row meets for that article-column**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>1430</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>732</td>\n",
       "      <td>rapidly build machine learning flows with dsx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>1429</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>43</td>\n",
       "      <td>deep learning with tensorflow course by big da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>109</td>\n",
       "      <td>tensorflow quick tips</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>1232</td>\n",
       "      <td>country statistics: life expectancy at birth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>310</td>\n",
       "      <td>time series prediction using recurrent neural ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>1293</td>\n",
       "      <td>finding optimal locations of new store using d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4664</th>\n",
       "      <td>1406</td>\n",
       "      <td>uci: iris</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>1406</td>\n",
       "      <td>uci: iris</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>329</td>\n",
       "      <td>introduction to market basket analysis in python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>585</td>\n",
       "      <td>tidyverse practice: mapping large european cities</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>310</td>\n",
       "      <td>time series prediction using recurrent neural ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>1305</td>\n",
       "      <td>gosales transactions for naive bayes model</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8429</th>\n",
       "      <td>1052</td>\n",
       "      <td>access db2 warehouse on cloud and db2 with python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11083</th>\n",
       "      <td>151</td>\n",
       "      <td>jupyter notebook tutorial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18903</th>\n",
       "      <td>1391</td>\n",
       "      <td>sudoku</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19307</th>\n",
       "      <td>981</td>\n",
       "      <td>super fast string matching in python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19308</th>\n",
       "      <td>910</td>\n",
       "      <td>working with ibm cloud object storage in python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19309</th>\n",
       "      <td>768</td>\n",
       "      <td>python if statements explained (python for dat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19379</th>\n",
       "      <td>1400</td>\n",
       "      <td>uci ml repository: chronic kidney disease data...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19695</th>\n",
       "      <td>1427</td>\n",
       "      <td>use xgboost, scikit-learn &amp; ibm watson machine...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19700</th>\n",
       "      <td>346</td>\n",
       "      <td>fighting gerrymandering: using data science to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19708</th>\n",
       "      <td>1439</td>\n",
       "      <td>working with ibm cloud object storage in r</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20078</th>\n",
       "      <td>494</td>\n",
       "      <td>python for loops explained (python for data sc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20081</th>\n",
       "      <td>1183</td>\n",
       "      <td>categorize urban density</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20082</th>\n",
       "      <td>585</td>\n",
       "      <td>tidyverse practice: mapping large european cities</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20083</th>\n",
       "      <td>1183</td>\n",
       "      <td>categorize urban density</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20239</th>\n",
       "      <td>668</td>\n",
       "      <td>shiny: a data scientist’s best friend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20248</th>\n",
       "      <td>1431</td>\n",
       "      <td>visualize car data with brunel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20252</th>\n",
       "      <td>1431</td>\n",
       "      <td>visualize car data with brunel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20320</th>\n",
       "      <td>968</td>\n",
       "      <td>shiny 0.13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20322</th>\n",
       "      <td>268</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20325</th>\n",
       "      <td>668</td>\n",
       "      <td>shiny: a data scientist’s best friend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20327</th>\n",
       "      <td>525</td>\n",
       "      <td>new shiny cheat sheet and video tutorial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21078</th>\n",
       "      <td>1368</td>\n",
       "      <td>putting a human face on machine learning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21087</th>\n",
       "      <td>1185</td>\n",
       "      <td>classify tumors with machine learning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>1185</td>\n",
       "      <td>classify tumors with machine learning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22032</th>\n",
       "      <td>390</td>\n",
       "      <td>introducing ibm watson studio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22048</th>\n",
       "      <td>1363</td>\n",
       "      <td>predict loan applicant behavior with tensorflo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22054</th>\n",
       "      <td>1363</td>\n",
       "      <td>predict loan applicant behavior with tensorflo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23401</th>\n",
       "      <td>1436</td>\n",
       "      <td>welcome to pixiedust</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24690</th>\n",
       "      <td>1052</td>\n",
       "      <td>access db2 warehouse on cloud and db2 with python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24733</th>\n",
       "      <td>1170</td>\n",
       "      <td>apache spark lab, part 1: basic concepts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24793</th>\n",
       "      <td>1170</td>\n",
       "      <td>apache spark lab, part 1: basic concepts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24839</th>\n",
       "      <td>626</td>\n",
       "      <td>analyze db2 warehouse on cloud data in rstudio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id                                              title  user_id\n",
       "0            1430  using pixiedust for fast, flexible, and easier...        1\n",
       "268          1430  using pixiedust for fast, flexible, and easier...        1\n",
       "1143          732      rapidly build machine learning flows with dsx        1\n",
       "1562         1429         use deep learning for image classification        1\n",
       "1710           43  deep learning with tensorflow course by big da...        1\n",
       "1712          109                              tensorflow quick tips        1\n",
       "2047         1232       country statistics: life expectancy at birth        1\n",
       "3839          310  time series prediction using recurrent neural ...        1\n",
       "4042         1293  finding optimal locations of new store using d...        1\n",
       "4664         1406                                          uci: iris        1\n",
       "5209         1406                                          uci: iris        1\n",
       "5822          329   introduction to market basket analysis in python        1\n",
       "5840          585  tidyverse practice: mapping large european cities        1\n",
       "6615          310  time series prediction using recurrent neural ...        1\n",
       "8345         1305         gosales transactions for naive bayes model        1\n",
       "8429         1052  access db2 warehouse on cloud and db2 with python        1\n",
       "11083         151                          jupyter notebook tutorial        1\n",
       "18903        1391                                             sudoku        1\n",
       "19307         981               super fast string matching in python        1\n",
       "19308         910    working with ibm cloud object storage in python        1\n",
       "19309         768  python if statements explained (python for dat...        1\n",
       "19379        1400  uci ml repository: chronic kidney disease data...        1\n",
       "19695        1427  use xgboost, scikit-learn & ibm watson machine...        1\n",
       "19700         346  fighting gerrymandering: using data science to...        1\n",
       "19708        1439         working with ibm cloud object storage in r        1\n",
       "20078         494  python for loops explained (python for data sc...        1\n",
       "20081        1183                           categorize urban density        1\n",
       "20082         585  tidyverse practice: mapping large european cities        1\n",
       "20083        1183                           categorize urban density        1\n",
       "20239         668              shiny: a data scientist’s best friend        1\n",
       "20248        1431                     visualize car data with brunel        1\n",
       "20252        1431                     visualize car data with brunel        1\n",
       "20320         968                                       shiny 0.13.0        1\n",
       "20322         268                      sector correlations shiny app        1\n",
       "20325         668              shiny: a data scientist’s best friend        1\n",
       "20327         525           new shiny cheat sheet and video tutorial        1\n",
       "21078        1368           putting a human face on machine learning        1\n",
       "21087        1185              classify tumors with machine learning        1\n",
       "21460        1185              classify tumors with machine learning        1\n",
       "22032         390                     introducing ibm watson studio         1\n",
       "22048        1363  predict loan applicant behavior with tensorflo...        1\n",
       "22054        1363  predict loan applicant behavior with tensorflo...        1\n",
       "23401        1436                               welcome to pixiedust        1\n",
       "24690        1052  access db2 warehouse on cloud and db2 with python        1\n",
       "24733        1170           apache spark lab, part 1: basic concepts        1\n",
       "24793        1170           apache spark lab, part 1: basic concepts        1\n",
       "24839         626  analyze db2 warehouse on cloud data in rstudio...        1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "df[df.user_id==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of articles that user 1 read\n",
    "df[df.user_id==1].article_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    user_item_df = df.groupby(['user_id','article_id']).count().astype('int').unstack()\n",
    "    user_item_df = (~user_item_df.isna())*1\n",
    "    user_item = user_item_df.values\n",
    "    \n",
    "    return user_item, user_item_df\n",
    "\n",
    "user_item, user_item_df = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5149, 714)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array version\n",
    "user_item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>1434</th>\n",
       "      <th>1435</th>\n",
       "      <th>1436</th>\n",
       "      <th>1437</th>\n",
       "      <th>1439</th>\n",
       "      <th>1440</th>\n",
       "      <th>1441</th>\n",
       "      <th>1442</th>\n",
       "      <th>1443</th>\n",
       "      <th>1444</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5149 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                                               ...            \\\n",
       "article_id  0    2    4    8    9    12   14   15   16   18    ... 1434 1435   \n",
       "user_id                                                        ...             \n",
       "1              0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "2              0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "3              0    0    0    0    0    1    0    0    0    0  ...    0    0   \n",
       "4              0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "5              0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "...          ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "5145           0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "5146           0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "5147           0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "5148           0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "5149           0    0    0    0    0    0    0    0    1    0  ...    0    0   \n",
       "\n",
       "                                                    \n",
       "article_id 1436 1437 1439 1440 1441 1442 1443 1444  \n",
       "user_id                                             \n",
       "1             1    0    1    0    0    0    0    0  \n",
       "2             0    0    0    0    0    0    0    0  \n",
       "3             1    0    0    0    0    0    0    0  \n",
       "4             0    0    0    0    0    0    0    0  \n",
       "5             0    0    0    0    0    0    0    0  \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "5145          0    0    0    0    0    0    0    0  \n",
       "5146          0    0    0    0    0    0    0    0  \n",
       "5147          0    0    0    0    0    0    0    0  \n",
       "5148          0    0    0    0    0    0    0    0  \n",
       "5149          0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5149 rows x 714 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe version\n",
    "user_item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check our function with user 1 data\n",
    "user_item.sum(axis=1)[0] == 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"user-user\">3. Similar Users and Collaborative Filtering.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the function below which should take a user_id and provide an ordered list of the most similar users to that user (from most similar to least similar). \n",
    "\n",
    "The key question here is what similarity measure we use. \n",
    "\n",
    "Given the type of our data and goal, the following two distance functions probably make more sense:\n",
    "\n",
    "- **cosine distance**: emphasize more on the similarity between users.\n",
    "\n",
    "\n",
    "- **dot product**: favor those users and items that are more active and more popular.\n",
    "\n",
    "\n",
    "We decide to go with dot product first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar user with respect to dot product\n",
    "\n",
    "def find_similar_users(user_id, user_item=user_item_df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # fillna for user_item\n",
    "    user_item.fillna(0, inplace=True)\n",
    "    # compute similarity of each user to the provided user\n",
    "    similarities = np.matmul(user_item.drop(user_id, axis=0).values, user_item.loc[user_id].values.reshape(-1,1))\n",
    "    similarities = pd.DataFrame(data=similarities, index=user_item.drop(user_id, axis=0).index, columns=['score'])\n",
    "    # sort by similarity\n",
    "    similarities = similarities.sort_values('score', ascending=False)\n",
    "    # create list of just the ids\n",
    "    most_similar_users = list(similarities.index)\n",
    "    \n",
    "       \n",
    "    return most_similar_users # return a list of the users in order from most to least similar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933, 23, 3782, 203, 4459, 3870, 131, 46, 4201, 395]\n",
      "The 5 most similar users to user 3933 are: [1, 23, 3782, 4459, 203]\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_df.loc[3782].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_df.loc[23].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_df.loc[4459].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use these similar users to find articles you can recommend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, a function that return the article ids and names that a user have read.\n",
    "def get_user_articles(user_id, user_item=user_item_df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    # \n",
    "    mask = (user_item_df.loc[user_id]!=0)\n",
    "    \n",
    "    article_ids = list(user_item_df.columns.get_level_values(1)[mask])\n",
    "    article_names = get_article_names(article_ids)\n",
    "    \n",
    "    return article_ids, article_names # return the ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbor-based recommendation\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    similar_users = find_similar_users(user_id)\n",
    "    seen_articles = get_user_articles(user_id)[0]\n",
    "    recs=[]\n",
    "    \n",
    "    for user in similar_users:\n",
    "        user_articles = get_user_articles(user)[0]\n",
    "        \n",
    "        if user_articles:\n",
    "            rec = [x for x in user_articles if x not in seen_articles+recs]\n",
    "            recs.extend(rec)\n",
    "            \n",
    "        if len(recs)>=m:\n",
    "            break\n",
    "    \n",
    "    recs = recs[:m]  \n",
    "    \n",
    "    return recs # return your recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this week in data science (april 18, 2017)',\n",
       " 'timeseries data analysis of iot events by using jupyter notebook',\n",
       " 'got zip code data? prep it for analytics. – ibm watson data lab – medium',\n",
       " 'higher-order logistic regression for large datasets',\n",
       " 'using machine learning to predict parking difficulty',\n",
       " 'deep forest: towards an alternative to deep neural networks',\n",
       " 'experience iot with coursera',\n",
       " 'using brunel in ipython/jupyter notebooks',\n",
       " 'graph-based machine learning',\n",
       " 'the 3 kinds of context: machine learning and the art of the frame']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Results\n",
    "get_article_names(user_user_recs(1, 10)) # Return 10 recommendations for user 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving our model:\n",
    "\n",
    "* In the above, we choose the order arbitrarily when we obtain users who are all the same closeness to a given user\n",
    "\n",
    "\n",
    "* Next, we should improve our model by ranking the users that have same distant to our client.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort users based on similarities and then number of article read\n",
    "def get_top_sorted_users(user_id, df=df, user_item=user_item_df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item_df - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    # fillna for user_item\n",
    "    user_item.fillna(0, inplace=True)\n",
    "    # reshape the user_id row to column\n",
    "    user_column = user_item.loc[user_id].values.reshape(-1,1)\n",
    "    # column of ones\n",
    "    ones_column = np.ones_like(user_column)\n",
    "    # concatenate the two columns\n",
    "    columns = np.concatenate([user_column, ones_column], axis=1)\n",
    "    # compute similarity of each user to the provided user, as well as number of interaction of each user\n",
    "    similarities = np.matmul(user_item.drop(user_id, axis=0).values, columns)\n",
    "    # transform into dataframe\n",
    "    similarities = pd.DataFrame(data=similarities, index=user_item.drop(user_id, axis=0).index, columns=['similarity','num_interactions']) \n",
    "    # sort values\n",
    "    neighbors_df = similarities.sort_values(['similarity','num_interactions'], ascending=False)\n",
    "    \n",
    "    \n",
    "    return neighbors_df # Return the dataframe specified in the doc_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>17</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5141</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5148 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         similarity  num_interactions\n",
       "user_id                              \n",
       "3933             35                35\n",
       "23               17               135\n",
       "3782             17               135\n",
       "203              15                96\n",
       "4459             15                96\n",
       "...             ...               ...\n",
       "5141              0                 1\n",
       "5144              0                 1\n",
       "5147              0                 1\n",
       "5148              0                 1\n",
       "5149              0                 1\n",
       "\n",
       "[5148 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_sorted_users(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    similar_users = get_top_sorted_users(user_id).index.values\n",
    "    seen_articles = get_user_articles(user_id)[0]\n",
    "    recs=[]\n",
    "    \n",
    "    for user in similar_users:\n",
    "        user_articles = get_user_articles(user)[0]\n",
    "        \n",
    "        if user_articles:\n",
    "            rec = [x for x in user_articles if x not in seen_articles+recs]\n",
    "            recs.extend(rec)\n",
    "            \n",
    "        if len(recs)>=m:\n",
    "            break\n",
    "    \n",
    "    recs = recs[:m]  \n",
    "    \n",
    "    rec_names = get_article_names(recs)\n",
    "    \n",
    "    \n",
    "    return recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "[12, 14, 29, 33, 43, 51, 109, 111, 130, 142]\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['timeseries data analysis of iot events by using jupyter notebook', 'got zip code data? prep it for analytics. – ibm watson data lab – medium', 'experience iot with coursera', 'using brunel in ipython/jupyter notebooks', 'deep learning with tensorflow course by big data university', 'modern machine learning algorithms', 'tensorflow quick tips', 'tidy up your jupyter notebooks with scripts', \"feature importance and why it's important\", 'neural networks for beginners: popular types and applications']\n"
     ]
    }
   ],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
